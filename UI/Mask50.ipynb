{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
      "Installing collected packages: pafy\n",
      "Successfully installed pafy-0.5.5\n",
      "Collecting youtube-dl\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/43/1f586e49e68f8b41c4be416302bf96ddd5040b0e744b5902d51063795eb9/youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 273kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: youtube-dl\n",
      "Successfully installed youtube-dl-2021.6.6\n",
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/d6/4b6268fad900fcb064e4344aa563b22688f0b38dcd857b500b2b5cc445c6/python_dotenv-0.19.0-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.19.0\n",
      "Collecting facenet-pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/18/e8/5ea742737665ba9396a8a2be3d2e2b49a13804b56a7e7bb101e8731ade8f/facenet_pytorch-2.5.2-py3-none-any.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 271kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision->facenet-pytorch)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision->facenet-pytorch)\n",
      "Installing collected packages: facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "\n",
    "class FastMTCNN(object):\n",
    "    def __init__(self, stride, resize=1, *args, **kwargs):\n",
    "        self.stride = stride\n",
    "        self.resize = resize\n",
    "        self.mtcnn = MTCNN(*args, **kwargs)\n",
    "        \n",
    "    def __call__(self, frames):\n",
    "        if self.resize != 1:\n",
    "            frames = [\n",
    "                cv2.resize(f, (int(f.shape[1] * self.resize), int(f.shape[0] * self.resize)))\n",
    "                    for f in frames\n",
    "            ]\n",
    "                      \n",
    "        boxes, probs = self.mtcnn.detect(frames[::self.stride])\n",
    "\n",
    "        faces = []\n",
    "        for i, frame in enumerate(frames):\n",
    "            box_ind = int(i / self.stride)\n",
    "            if boxes[box_ind] is None:\n",
    "                continue\n",
    "            for box in boxes[box_ind]:\n",
    "                box = [int(b) for b in box]\n",
    "                faces.append(frame[box[1]:box[3], box[0]:box[2]])\n",
    "        \n",
    "        return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-4-9699a7c4b965>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-9699a7c4b965>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    image = PIL.Image.fromarray(image)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "fast_mtcnn = FastMTCNN(\n",
    "    stride=4,\n",
    "    resize=1,\n",
    "    margin=14,\n",
    "    factor=0.6,\n",
    "    keep_all=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "\n",
    "load_dotenv()\n",
    "outframe = None\n",
    "url = \"https://youtu.be/7PYzSXHd6U4\"\n",
    "#livestream = VideoStream()\n",
    "#linkedstream = LinkedStream(url)\n",
    "camera = USBCamera(width=224, height=224, capture_fps=30, capture_device=0) # confirm the capture_device number\n",
    "camera.running = True\n",
    "print(\"camera created\")\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius_size = getenv('DEFAULT_RADIUS')\n",
    "default_radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "default_duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "message = None\n",
    "\n",
    "#working values\n",
    "radius_size = getenv('DEFAULT_RADIUS')\n",
    "radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "duration = getenv('DEFAULT_DURATION')\n",
    "duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def change_source(change):\n",
    "    global active\n",
    "    active = change['new']\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['Live', 'Playback'], value='Live')\n",
    "state_widget.observe(change_source, names='value')\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "def execute(change):\n",
    "    frame = change['new']\n",
    "    boxes, probs = fast_mtcnn(frame)\n",
    "    if boxes is not None:\n",
    "        print(\"found face\")\n",
    "        #for box, prob in zip(boxes, probs):\n",
    "        #    processed = preprocess(frame)\n",
    "        #    output = model(processed)\n",
    "        #    output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "        #    category_index = output.argmax()\n",
    "        #    if output[category_index] > 0.6:\n",
    "        #        color = (0, 0, 255) if category_index else (0, 255, 0)\n",
    "        #        label = \"No MASK\" if category_index else \"MASK\"\n",
    "        #        print(box)\n",
    "    #draw_objects(image, counts, objects, peaks)# try this for multiple hand pose prediction\n",
    "    image_widget.value = bgr8_to_jpeg(frame[:, ::-1, :])\n",
    "\n",
    "display_handle = display(state_widget, image_widget)\n",
    "while True:\n",
    "    execute({'new': camera.value})\n",
    "    camera.observe(execute, names='value')\n",
    "    camera.unobserve_all()\n",
    "    #img = cv2.rectangle(frame, start_point, end_point, color, 2)  # draw class box\n",
    "    #        text = \"{}:{:.2f}\".format(label, score[0])\n",
    "    #        cv2.putText(frame, text, start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)  # print class type with score\n",
    "    #        frame = cv2.rectangle(frame, start_point, end_point, color, 2)\n",
    "    #draw.rectangle(box.tolist(), outline=(255,0,0), width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
