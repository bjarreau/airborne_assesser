{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
      "Installing collected packages: pafy\n",
      "Successfully installed pafy-0.5.5\n",
      "Collecting youtube-dl\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/43/1f586e49e68f8b41c4be416302bf96ddd5040b0e744b5902d51063795eb9/youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 278kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: youtube-dl\n",
      "Successfully installed youtube-dl-2021.6.6\n",
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/d6/4b6268fad900fcb064e4344aa563b22688f0b38dcd857b500b2b5cc445c6/python_dotenv-0.19.0-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.19.0\n",
      "Collecting facenet-pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/18/e8/5ea742737665ba9396a8a2be3d2e2b49a13804b56a7e7bb101e8731ade8f/facenet_pytorch-2.5.2-py3-none-any.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 273kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision->facenet-pytorch)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision->facenet-pytorch)\n",
      "Installing collected packages: facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "camera created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7be8273e0949c79de22280ec2f2c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=('Live', 'Playback'), value='Live')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef4ae09d90945e9b1726b4f610b7e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f284d7ac9993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mdisplay_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_widget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munobserve_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f284d7ac9993>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mface_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             )\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mboxes_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_inds_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateBoundingBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimage_inds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_inds_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mgenerateBoundingBox\u001b[0;34m(reg, probs, scale, thresh)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcellsize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mboundingbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import display, Image\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "from my_heatmap_generator import HMap\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "\n",
    "load_dotenv()\n",
    "HMAP = []\n",
    "outframe = None\n",
    "url = \"https://youtu.be/7PYzSXHd6U4\"\n",
    "camera = USBCamera(width=224, height=224, capture_fps=30, capture_device=0) # confirm the capture_device number\n",
    "camera.running = True\n",
    "print(\"camera created\")\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius_size = getenv('DEFAULT_RADIUS')\n",
    "default_radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "default_duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "message = None\n",
    "\n",
    "#working values\n",
    "radius_size = getenv('DEFAULT_RADIUS')\n",
    "radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "duration = getenv('DEFAULT_DURATION')\n",
    "duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def change_source(change):\n",
    "    global active\n",
    "    active = change['new']\n",
    "\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['Live', 'Playback'], value='Live')\n",
    "state_widget.observe(change_source, names='value')\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "def generate_heatmap(image, obj_meta, confidence, stream_idx):\n",
    "    hmap = HMAP[stream_idx]\n",
    "    rect_params = obj_meta.rect_params\n",
    "    x1 = int(rect_params.left)\n",
    "    y2 = int(rect_params.top)\n",
    "    x2 = int(rect_params.left) + int(rect_params.width)\n",
    "    y2 = int(rect_params.top) + int(rect_params.height)\n",
    "    hmap.apply_color_map(x1,y1,x2,y2)\n",
    "    return hmap.heatmap\n",
    "\n",
    "def execute(change):\n",
    "    frame = change['new']\n",
    "    frame = PIL.Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    width, height = frame.size[:2]\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    face_only = None\n",
    "    if boxes is not None:\n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        for box in boxes:\n",
    "            rectangle = (box[0]-20, box[1]-20, box[2]+20, box[3]+20)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            face_only = face_only.resize((224, 224))\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            #color = (255, 0, 0)\n",
    "            #if output[category_index] > 0.6:\n",
    "            #    color = (255, 0, 0) if category_index else (0, 255, 0)\n",
    "            HMAP.append(HMap(height, width))\n",
    "            for hmap in HMAP:\n",
    "                tmp = hmap.apply_color_map(frame, int((box[0]+box[2])/2), int((box[1]+box[3])/2))\n",
    "                frame = PIL.Image.fromarray(tmp, \"RGB\")\n",
    "            #draw.rectangle(box.tolist(), outline=color, width=6)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "\n",
    "display_handle = display(state_widget, image_widget)\n",
    "while True:\n",
    "    execute({'new': camera.value})\n",
    "    camera.observe(execute, names='value')\n",
    "    camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
