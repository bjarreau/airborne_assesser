{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision->facenet-pytorch)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision->facenet-pytorch)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.4ubuntu1).\n",
      "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 101 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "liblapack-dev is already the newest version (3.7.1-4ubuntu1).\n",
      "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 101 not upgraded.\n",
      "Collecting face_recognition\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
      "Collecting Click>=6.0 (from face_recognition)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl (97kB)\n",
      "\u001b[K    100% |################################| 102kB 1.3MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from face_recognition)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
      "\u001b[K    100% |################################| 100.2MB 5.2kB/s eta 0:00:01   20% |######                          | 20.7MB 22.5MB/s eta 0:00:04    41% |#############                   | 41.9MB 25.4MB/s eta 0:00:03    45% |##############                  | 45.9MB 24.5MB/s eta 0:00:03    54% |#################               | 54.4MB 24.3MB/s eta 0:00:02    60% |###################             | 60.2MB 22.8MB/s eta 0:00:02    62% |###################             | 62.5MB 21.4MB/s eta 0:00:02    64% |####################            | 64.9MB 24.0MB/s eta 0:00:02    67% |#####################           | 67.3MB 24.2MB/s eta 0:00:02    72% |#######################         | 73.0MB 23.8MB/s eta 0:00:02    74% |#######################         | 74.2MB 23.6MB/s eta 0:00:02    75% |########################        | 75.4MB 26.1MB/s eta 0:00:01    91% |#############################   | 91.4MB 24.9MB/s eta 0:00:01    96% |############################### | 97.1MB 24.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from Click>=6.0->face_recognition)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->Click>=6.0->face_recognition)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->Click>=6.0->face_recognition)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Running setup.py bdist_wheel for face-recognition-models ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: Click, face-recognition-models, face-recognition\n",
      "Successfully installed Click-8.0.1 face-recognition-1.3.0 face-recognition-models-0.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!git clone --recursive https://github.com/dusty-nv/jetson-inference\n",
    "#!{sys.executable} -m pip install pafy\n",
    "#!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "from my_heatmap_generator import HMap\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "\n",
    "print(\"model loaded\")\n",
    "outframe = None\n",
    "url = \"https://youtu.be/7PYzSXHd6U4\"\n",
    "load_dotenv()\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius_size = getenv('DEFAULT_RADIUS')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "radius = int(getenv('DEFAULT_RADIUS'))\n",
    "duration = int(getenv('DEFAULT_DURATION'))\n",
    "\n",
    "def on_value_change(change):\n",
    "    print(\"Value change\")\n",
    "    radius = radius_slider.value\n",
    "    duration = duration_slider.value\n",
    "\n",
    "duration_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 2,\n",
    "    max = 30,\n",
    "    step=1,\n",
    "    description='Airborne Duration:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "radius_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 10,\n",
    "    max = 200,\n",
    "    step=1,\n",
    "    description='Radius:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9916193551e4aafb7eea7cbb339b64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d991819de0435489451650b0dca21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=20, description='Airborne Duration:', max=30, min=2), IntSlider(value=20, descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "HMAP = []\n",
    "camera = USBCamera(width=224, height=224, capture_fps=30, capture_device=0)\n",
    "camera.running = True\n",
    "camera.value\n",
    "print(\"camera created\")\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "def execute(change):\n",
    "    global hmap, radius, duration\n",
    "    frame = change['new']\n",
    "    frame =cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    frame = PIL.Image.fromarray(frame)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            min_x = box[0] if box[0]-50 > 0 else 0\n",
    "            max_x = box[2] if box[2]+50 < 224 else 224\n",
    "            min_y = box[1] if box[1]-50 > 0 else 0\n",
    "            max_y = box[3] if box[3]+50 < 224 else 224\n",
    "            rectangle = (min_x, min_y, max_x, max_y)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            face_only = face_only.resize((224, 224))\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            radius = radius_slider.value\n",
    "            duration = duration_slider.value\n",
    "            print(output)\n",
    "            #if output[category_index] < 0.55:\n",
    "            #    category_index = 0\n",
    "            hmap = HMap(box, category_index)\n",
    "            HMAP.append(hmap)\n",
    "            frame = hmap.draw_map(frame, radius, duration)\n",
    "    for hmap in HMAP:\n",
    "        frame = hmap.draw_map(frame, radius, duration)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "\n",
    "camera.observe(execute, names='value')\n",
    "display_handle = display(image_widget, widgets.HBox([duration_slider, radius_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
