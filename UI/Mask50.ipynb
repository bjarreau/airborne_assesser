{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl\n",
      "Installing collected packages: pafy\n",
      "Successfully installed pafy-0.5.5\n",
      "Collecting youtube-dl\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/43/1f586e49e68f8b41c4be416302bf96ddd5040b0e744b5902d51063795eb9/youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 265kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: youtube-dl\n",
      "Successfully installed youtube-dl-2021.6.6\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision->facenet-pytorch)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision->facenet-pytorch)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "from my_heatmap_generator import HMap\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "\n",
    "print(\"model loaded\")\n",
    "outframe = None\n",
    "url = \"https://youtu.be/hZgWMSM0uyk\"\n",
    "load_dotenv()\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius = getenv('DEFAULT_RADIUS')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "radius = int(getenv('DEFAULT_RADIUS'))\n",
    "duration = int(getenv('DEFAULT_DURATION'))\n",
    "\n",
    "def on_value_change(change):\n",
    "    print(\"Value change\")\n",
    "    radius = radius_slider.value\n",
    "    duration = duration_slider.value\n",
    "\n",
    "duration_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 2,\n",
    "    max = 30,\n",
    "    step=1,\n",
    "    description='Airborne Duration:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "radius_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 10,\n",
    "    max = 124,\n",
    "    step=1,\n",
    "    description='Radius:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "def reset_values(b):\n",
    "    radius_slider.value = int(default_radius)\n",
    "    duration_slider.value = int(default_duration)\n",
    "\n",
    "reset_button = widgets.Button(description = \"Reset\")\n",
    "reset_button.on_click(reset_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMAP = []\n",
    "camera = USBCamera(width=224, height=224, capture_fps=30, capture_device=0)\n",
    "camera.running = True\n",
    "camera.value\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "def execute(change):\n",
    "    global hmap, radius, duration\n",
    "    frame = change['new']\n",
    "    frame =cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    frame = PIL.Image.fromarray(frame)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            xrange = int((box[2] - box[0])/2)\n",
    "            yrange = int((box[3] - box[1])/2)\n",
    "            min_x = box[0] - xrange if box[0]-xrange > 0 else 0\n",
    "            max_x = box[2] + xrange if box[2]+xrange < 224 else 224\n",
    "            min_y = box[1] - yrange if box[1]-yrange > 0 else 0\n",
    "            max_y = box[3] + yrange if box[3]+yrange < 224 else 224\n",
    "            rectangle = (min_x, min_y, max_x, max_y)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            new_width  = int(224 * face_only.size[0] / face_only.size[1])\n",
    "            face_only = face_only.resize((new_width, 224))\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            radius = radius_slider.value\n",
    "            duration = duration_slider.value\n",
    "            if output[category_index] < 0.6:\n",
    "                category_index = 1\n",
    "            hmap = HMap(box, category_index)\n",
    "            HMAP.append(hmap)\n",
    "            frame = hmap.draw_map(frame, radius, duration)\n",
    "    for hmap in HMAP:\n",
    "        frame = hmap.draw_map(frame, radius, duration)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "\n",
    "camera.observe(execute, names='value')\n",
    "display_handle = display(image_widget, widgets.HBox([duration_slider, radius_slider, reset_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb0da93cb7147db8f9fb1ddb9be74b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='https://youtu.be/hZgWMSM0uyk', placeholder='https://youtu.be/hZgWMSM0uyk'), Button(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93622009785492f8470068693ab0319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d00415e4c604c28a86c520856820ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=20, description='Airborne Duration:', max=30, min=2), IntSlider(value=20, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-678615e45868>\", line 29, in startVid\n",
      "    executeVid(frame)\n",
      "  File \"<ipython-input-2-678615e45868>\", line 58, in executeVid\n",
      "    new_width  = int(224 * face_only.size[0] / face_only.size[1])\n",
      "ZeroDivisionError: division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import pafy\n",
    "\n",
    "HMAP = []\n",
    "urlPafy = pafy.new(url)\n",
    "link = urlPafy.getbest(preftype=\"mp4\")\n",
    "video = cv2.VideoCapture(link.url)\n",
    "playing = False\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "urlbox = widgets.Text(\n",
    "    value=url,\n",
    "    placeholder=url,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def startVid():\n",
    "    global playing\n",
    "    playing = True\n",
    "    while(playing):\n",
    "        try:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            lines, columns, _ = frame.shape\n",
    "            executeVid(frame)\n",
    "        except KeyboardInterrupt: \n",
    "            video.release()\n",
    "            break\n",
    "\n",
    "def submit_url(b):\n",
    "    global playing\n",
    "    playing = False\n",
    "    urlPafy = pafy.new(urlbox.value)\n",
    "    link = urlPafy.getbest(preftype=\"mp4\")\n",
    "    video = cv2.VideoCapture(link.url)\n",
    "    t = Thread(target = startVid, daemon = True)\n",
    "    t.start()\n",
    "\n",
    "submit_button = widgets.Button(description = \"Submit\")\n",
    "submit_button.on_click(submit_url)\n",
    "\n",
    "def executeVid(frame):\n",
    "    global hmap, radius, duration\n",
    "    frame =cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    frame = PIL.Image.fromarray(frame)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            xrange = int((box[2] - box[0])/2)\n",
    "            yrange = int((box[3] - box[1])/2)\n",
    "            min_x = box[0] - xrange if box[0]-xrange > 0 else 0\n",
    "            max_x = box[2] + xrange if box[2]+xrange < 224 else 224\n",
    "            min_y = box[1] - yrange if box[1]-yrange > 0 else 0\n",
    "            max_y = box[3] + yrange if box[3]+yrange < 224 else 224\n",
    "            rectangle = (min_x, min_y, max_x, max_y)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            new_width  = int(224 * face_only.size[0] / face_only.size[1])\n",
    "            face_only = face_only.resize((new_width, 224))\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            radius = radius_slider.value\n",
    "            duration = duration_slider.value\n",
    "            if output[category_index] < 0.6:\n",
    "                category_index = 1\n",
    "            hmap = HMap(box, category_index)\n",
    "            HMAP.append(hmap)\n",
    "            frame = hmap.draw_map(frame, radius, duration)\n",
    "    for hmap in HMAP:\n",
    "        frame = hmap.draw_map(frame, radius, duration)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "    \n",
    "\n",
    "display_handle = display(widgets.HBox([urlbox, submit_button]), image_widget, widgets.HBox([duration_slider, radius_slider, reset_button]))\n",
    "t = Thread(target = startVid, daemon = True)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
