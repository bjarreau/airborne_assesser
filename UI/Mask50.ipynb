{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "camera created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f086d544a6534bf2994bc4d67fa64e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=('Live', 'Playback'), value='Live')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ccbf4d4f214b47936fcb7ebe009935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87f8070ecfdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mdisplay_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_widget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munobserve_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-87f8070ecfdf>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             )\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mboxes_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_inds_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateBoundingBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimage_inds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_inds_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mgenerateBoundingBox\u001b[0;34m(reg, probs, scale, thresh)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcellsize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mboundingbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import display, Image\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "\n",
    "load_dotenv()\n",
    "outframe = None\n",
    "url = \"https://youtu.be/7PYzSXHd6U4\"\n",
    "camera = USBCamera(width=224, height=224, capture_fps=30, capture_device=0) # confirm the capture_device number\n",
    "camera.running = True\n",
    "print(\"camera created\")\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius_size = getenv('DEFAULT_RADIUS')\n",
    "default_radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "default_duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "message = None\n",
    "\n",
    "#working values\n",
    "radius_size = getenv('DEFAULT_RADIUS')\n",
    "radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "duration = getenv('DEFAULT_DURATION')\n",
    "duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def change_source(change):\n",
    "    global active\n",
    "    active = change['new']\n",
    "\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['Live', 'Playback'], value='Live')\n",
    "state_widget.observe(change_source, names='value')\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "def execute(change):\n",
    "    frame = change['new']\n",
    "    frame = PIL.Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    if boxes is not None:\n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        for box in boxes:\n",
    "            face_only = frame.crop(box.tolist())\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            color = (255, 0, 0)\n",
    "            if output[category_index] > 0.6:\n",
    "                color = (255, 0, 0) if category_index else (0, 255, 0)\n",
    "            draw.rectangle(box.tolist(), outline=color, width=6)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "\n",
    "display_handle = display(state_widget, image_widget)\n",
    "while True:\n",
    "    execute({'new': camera.value})\n",
    "    camera.observe(execute, names='value')\n",
    "    camera.unobserve_all()\n",
    "    #img = cv2.rectangle(frame, start_point, end_point, color, 2)  # draw class box\n",
    "    #        text = \"{}:{:.2f}\".format(label, score[0])\n",
    "    #        cv2.putText(frame, text, start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)  # print class type with score\n",
    "    #        frame = cv2.rectangle(frame, start_point, end_point, color, 2)\n",
    "    #draw.rectangle(box.tolist(), outline=(255,0,0), width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
