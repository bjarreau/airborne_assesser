{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pafy in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages/Pillow-8.0.1-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from facenet-pytorch)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg (from facenet-pytorch)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->facenet-pytorch)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision->facenet-pytorch)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision->facenet-pytorch)\n",
      "Collecting ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./model')\n",
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from IPython.display import Image\n",
    "from my_heatmap_generator import HMap\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "\n",
    "print(\"models loaded\")\n",
    "outframe = None\n",
    "url = \"https://youtu.be/w_RxkekW7sE\"\n",
    "load_dotenv()\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius = getenv('DEFAULT_RADIUS')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "radius = int(getenv('DEFAULT_RADIUS'))\n",
    "duration = int(getenv('DEFAULT_DURATION'))\n",
    "\n",
    "def on_value_change(change):\n",
    "    print(\"Value change\")\n",
    "    radius = radius_slider.value\n",
    "    duration = duration_slider.value\n",
    "\n",
    "duration_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 2,\n",
    "    max = 30,\n",
    "    step=1,\n",
    "    description='Airborne Duration:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "radius_slider = widgets.IntSlider(\n",
    "    value=duration,\n",
    "    min = 10,\n",
    "    max = 124,\n",
    "    step=1,\n",
    "    description='Radius:',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "def reset_values(b):\n",
    "    radius_slider.value = int(default_radius)\n",
    "    duration_slider.value = int(default_duration)\n",
    "\n",
    "reset_button = widgets.Button(description = \"Reset\")\n",
    "reset_button.on_click(reset_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37210f66a4c94f0391dbd99d004a3ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='244', width='244')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9f5d510ad04b0780437c4407c23d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=20, description='Airborne Duration:', max=30, min=2), IntSlider(value=20, descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HMAP = []\n",
    "camera = USBCamera(width=244, height=244, capture_fps=30, capture_device=0)\n",
    "camera.running = True\n",
    "camera.value\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=244, height=244)\n",
    "\n",
    "def execute(change):\n",
    "    global hmap, radius, duration\n",
    "    frame = change['new']\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    frame = PIL.Image.fromarray(frame)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            xrange = (box[2] - box[0])\n",
    "            yrange = 1.5*(box[3] - box[1])\n",
    "            min_x = box[0] - xrange if box[0]-xrange > 0 else 0\n",
    "            max_x = box[2] + xrange if box[2]+xrange < 224 else 224\n",
    "            min_y = box[1] - yrange if box[1]-yrange > 0 else 0\n",
    "            max_y = box[3] + yrange if box[3]+yrange < 224 else 224\n",
    "            rectangle = (min_x, min_y, max_x, max_y)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            new_width  = int(224 * face_only.size[0] / face_only.size[1])\n",
    "            frame = face_only.resize((new_width, 224))\n",
    "            processed = preprocess(face_only)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            radius = radius_slider.value\n",
    "            duration = duration_slider.value\n",
    "            if output[category_index] < 0.6:\n",
    "                category_index = 1\n",
    "            hmap = HMap(box, category_index)\n",
    "            HMAP.append(hmap)\n",
    "            frame = hmap.draw_map(frame, radius, duration)\n",
    "    for hmap in HMAP:\n",
    "        frame = hmap.draw_map(frame, radius, duration)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "\n",
    "camera.observe(execute, names='value')\n",
    "display_handle = display(image_widget, widgets.HBox([duration_slider, radius_slider, reset_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ffmpeg' has no attribute 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7cf63fce458d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./stock/138033507-waitress-face-mask-serving-hap.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pipe:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rawvideo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpix_fmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb24'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture_stdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1920\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ffmpeg' has no attribute 'input'"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "HMAP = []\n",
    "video = cv2.VideoCapture('./stock/138033507-waitress-face-mask-serving-hap.mp4')\n",
    "playing = False\n",
    "\n",
    "def preprocess(image):\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=400, height=400)\n",
    "\n",
    "urlbox = widgets.Text(\n",
    "    value=url,\n",
    "    placeholder=url,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def executeVid(frame):\n",
    "    global hmap, radius, duration\n",
    "    frame =cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    frame = PIL.Image.fromarray(frame)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            xrange = (box[2] - box[0])\n",
    "            yrange = 1.5*(box[3] - box[1])\n",
    "            min_x = box[0] - xrange if box[0]-xrange > 0 else 0\n",
    "            max_x = box[2] + xrange if box[2]+xrange < 224 else 224\n",
    "            min_y = box[1] - yrange if box[1]-yrange > 0 else 0\n",
    "            max_y = box[3] + yrange if box[3]+yrange < 224 else 224\n",
    "            rectangle = (min_x, min_y, max_x, max_y)\n",
    "            face_only = frame.crop(rectangle)\n",
    "            if face_only.size[0] > 0 and face_only.size[1] > 0:\n",
    "                new_width  = int(224 * face_only.size[0] / face_only.size[1])\n",
    "                face_only = face_only.resize((new_width, 224))\n",
    "                processed = preprocess(face_only)\n",
    "                output = model(processed)\n",
    "                output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "                category_index = output.argmax()\n",
    "                radius = radius_slider.value\n",
    "                duration = duration_slider.value\n",
    "                if output[category_index] < 0.6:\n",
    "                    category_index = 1\n",
    "                hmap = HMap(box, category_index)\n",
    "                HMAP.append(hmap)\n",
    "                frame = hmap.draw_map(frame, radius, duration)\n",
    "    for hmap in HMAP:\n",
    "        frame = hmap.draw_map(frame, radius, duration)\n",
    "    buf = io.BytesIO()\n",
    "    frame.save(buf, format='JPEG')\n",
    "    image_widget.value = buf.getvalue()\n",
    "    \n",
    "def startVid():\n",
    "    global playing, video\n",
    "    playing = True\n",
    "    while(playing):\n",
    "        try:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            executeVid(frame)\n",
    "        except KeyboardInterrupt: \n",
    "            video.release()\n",
    "            break\n",
    "\n",
    "def submit_url(b):\n",
    "    global playing, video\n",
    "    playing = False\n",
    "    video.release()\n",
    "    video = cv2.VideoCapture(urlbox.value)\n",
    "    t = Thread(target = startVid, daemon = True)\n",
    "    t.start()\n",
    "\n",
    "submit_button = widgets.Button(description = \"Submit\")\n",
    "submit_button.on_click(submit_url)    \n",
    "display_handle = display(widgets.HBox([urlbox, submit_button]), image_widget, widgets.HBox([duration_slider, radius_slider, reset_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
