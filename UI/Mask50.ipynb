{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pafy\n",
    "!{sys.executable} -m pip install youtube-dl\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install facenet-pytorch\n",
    "\n",
    "import zmq\n",
    "import pafy\n",
    "import numpy as np\n",
    "import time\n",
    "from os import getenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import IPython\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from facenet_pytorch import MTCNN\n",
    "from VideoStream import VideoStream\n",
    "from LinkedStream import LinkedStream\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./model/my_model(1).pth'))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device='cuda:0')\n",
    "\n",
    "load_dotenv()\n",
    "outframe = None\n",
    "url = \"https://youtu.be/7PYzSXHd6U4\"\n",
    "#livestream = VideoStream()\n",
    "#linkedstream = LinkedStream(url)\n",
    "camera = USBCamera(width=224, height=224, capture_device=0) # confirm the capture_device number\n",
    "camera.running = True\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')\n",
    "print(\"camera created\")\n",
    "\n",
    "#defaults\n",
    "active = \"Live\"\n",
    "default_radius_size = getenv('DEFAULT_RADIUS')\n",
    "default_radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "default_duration = getenv('DEFAULT_DURATION')\n",
    "default_duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "message = None\n",
    "\n",
    "#working values\n",
    "radius_size = getenv('DEFAULT_RADIUS')\n",
    "radius_uom = getenv('DEFAULT_RADIUS_UOM')\n",
    "duration = getenv('DEFAULT_DURATION')\n",
    "duration_uom = getenv('DEFAULT_DURATION_UOM')\n",
    "\n",
    "def preprocess(image):\n",
    "    device = torch.device('cuda')\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def change_source(change):\n",
    "    global active\n",
    "    active = change['new']\n",
    "   \n",
    "state_widget = ipywidgets.ToggleButtons(options=['Live', 'Playback'], value='Live')\n",
    "state_widget.observe(change_source, names='value')\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "all_widget = ipywidgets.VBox([\n",
    "    state_widget,\n",
    "    image_widget\n",
    "])\n",
    "\n",
    "display_handle = display(all_widget)\n",
    "\n",
    "def execute(change):\n",
    "    frame = change['new']\n",
    "    boxes, probs = mtcnn.detect(frame) # TODO: THIS ISN'T DETECTING ANYTHING\n",
    "    if boxes is not None:\n",
    "        for box, prob, ld in zip(boxes, probs):\n",
    "            processed = preprocess(frame)\n",
    "            output = model(processed)\n",
    "            output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "            category_index = output.argmax()\n",
    "            if output[category_index] > 0.6:\n",
    "                color = (0, 0, 255) if category_index else (0, 255, 0)\n",
    "                label = \"No MASK\" if category_index else \"MASK\"\n",
    "                print(box)\n",
    "    #draw_objects(image, counts, objects, peaks)# try this for multiple hand pose prediction \n",
    "    image_widget.value = bgr8_to_jpeg(frame[:, ::-1, :])\n",
    "\n",
    "while True:\n",
    "    execute({'new': camera.value})\n",
    "    #(conf, frame) = livestream.read() if active == \"Live\" else linkedstream.read()\n",
    "    #small_frame = cv2.resize(frame, (int(frame.shape[0]/2), int(frame.shape[1]/2)), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    #img = cv2.rectangle(frame, start_point, end_point, color, 2)  # draw class box\n",
    "    #        text = \"{}:{:.2f}\".format(label, score[0])\n",
    "    #        cv2.putText(frame, text, start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)  # print class type with score\n",
    "    #        frame = cv2.rectangle(frame, start_point, end_point, color, 2)\n",
    "    #draw.rectangle(box.tolist(), outline=(255,0,0), width=6)\n",
    "    #d.update(frame)\n",
    "    #encode_parameters = [int(cv2.IMWRITE_JPEG_QUALITY),75]\n",
    "    #encode_state, encoded = cv2.imencode('.jpg', frame, encode_parameters)\n",
    "    #binary_image = encoded.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
